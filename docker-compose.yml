version: '3.8'

services:
  # Production ThreatIngestor
  threatingestor-prod:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: ai-threatingestor-prod
    ports:
      - "7862:7862"  # Dashboard
      - "11434:11434"  # Ollama API
    volumes:
      - ./data:/app/data
      - ./logs:/app/logs
      - threat_db:/app/threat_intelligence.db
    environment:
      - PYTHONUNBUFFERED=1
      - OLLAMA_HOST=0.0.0.0
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:7862/"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s

  # Development ThreatIngestor
  threatingestor-dev:
    build:
      context: .
      dockerfile: Dockerfile.dev
    container_name: ai-threatingestor-dev
    ports:
      - "7863:7862"  # Dashboard (different port for dev)
      - "11435:11434"  # Ollama API (different port for dev)
      - "8888:8888"  # Jupyter Lab
    volumes:
      - .:/app  # Mount entire project for development
      - dev_threat_db:/app/threat_intelligence.db
    environment:
      - PYTHONUNBUFFERED=1
      - OLLAMA_HOST=0.0.0.0
      - DEVELOPMENT=1
    profiles:
      - dev
    command: dashboard

  # Jupyter development environment
  jupyter-dev:
    build:
      context: .
      dockerfile: Dockerfile.dev
    container_name: ai-threatingestor-jupyter
    ports:
      - "8889:8888"  # Jupyter Lab
    volumes:
      - .:/app
      - dev_threat_db:/app/threat_intelligence.db
    environment:
      - PYTHONUNBUFFERED=1
      - DEVELOPMENT=1
    profiles:
      - dev
    command: jupyter

volumes:
  threat_db:
    driver: local
  dev_threat_db:
    driver: local

networks:
  default:
    driver: bridge
